# Extract filename from URL
file_name <- basename(file_url)
# Define the full path to save the file
file_path <- file.path(dest_dir, file_name)
# Download file
GET(file_url, write_disk(file_path, overwrite = TRUE))
cat("Downloaded:", file_name, "\n")
}
}
# Download .asc files
download_files(asc_url, "\\.asc$", dest_dir)
# Install required packages if not already installed
if (!require("httr")) install.packages("httr", dependencies = TRUE)
if (!require("rvest")) install.packages("rvest", dependencies = TRUE)
# Load required libraries
library(httr)
library(rvest)
# Define the URLs
asc_url <- "https://www.ncei.noaa.gov/data/noaa-global-surface-temperature/v6/access/timeseries/"
nc_url <- "https://www.ncei.noaa.gov/data/noaa-global-surface-temperature/v6/access/gridded/"
# Define the destination directory (relative path)
dest_dir <- "../data/raw/"
# Create destination directory if it does not exist
if (!dir.exists(dest_dir)) {
dir.create(dest_dir, recursive = TRUE)
}
# Function to download files from a given URL
download_files <- function(base_url, pattern, dest_dir) {
# Read the webpage
webpage <- read_html(base_url)
# Extract links that match the file extension pattern
links <- webpage %>%
html_nodes("a") %>%
html_attr("href")
# Filter links that match the pattern
matching_links <- links[grepl(pattern, links)]
# Define the full URLs of the files
file_urls <- paste0(base_url, matching_links)
# Download each file
for (file_url in file_urls) {
# Extract filename from URL
file_name <- basename(file_url)
# Define the full path to save the file
file_path <- file.path(dest_dir, file_name)
# Download file
GET(file_url, write_disk(file_path, overwrite = TRUE))
cat("Downloaded:", file_name, "\n")
}
}
# Download .asc files
download_files(asc_url, "\\.asc$", dest_dir)
# Download .nc files
download_files(nc_url, "\\.nc$", dest_dir)
install.packages('data.table')
library(data.table)
# List and read .asc files
file_list <- list.files(path = "../data/raw", pattern = "\\.asc$", full.names = TRUE)
combined_data <- rbindlist(lapply(file_list, fread))
# List and read .asc files with differing columns
file_list <- list.files(path = "../data/raw", pattern = "\\.asc$", full.names = TRUE)
# Read all files into a list, allowing for inconsistent columns
data_list <- lapply(file_list, fread, fill = TRUE)
# Combine data into a single data.table, filling missing columns
combined_data <- rbindlist(data_list, fill = TRUE)
View(combined_data)
# Save combined data to CSV
fwrite(combined_data, "../data/raw/combined_time_series.csv")
install.packages('ncdf4')
install.packages('raster')
library(data.table)
library(ncdf4)
library(raster)
# Use the first .nc file found (adjust if you need to process multiple files)
nc_file <- nc_files[1]
# List .nc files in the directory
nc_files <- list.files(path = nc_dir, pattern = "\\.nc$", full.names = TRUE)
dir <- "../data/raw/"
# List and read .asc files with differing columns
file_list <- list.files(path = dir, pattern = "\\.asc$", full.names = TRUE)
# Read all files into a list, allowing for inconsistent columns
data_list <- lapply(file_list, fread, fill = TRUE)
# Combine data into a single data.table, filling missing columns
combined_data <- rbindlist(data_list, fill = TRUE)
# Save combined data to CSV
fwrite(combined_data, dir+"/combined_time_series.csv")
# Save combined data to CSV
fwrite(combined_data, paste(dir,"/combined_time_series.csv"))
# Save combined data to CSV
fwrite(combined_data, paste0(dir,"/combined_time_series.csv"))
# List .nc files in the directory
nc_files <- list.files(path = dir, pattern = "\\.nc$", full.names = TRUE)
# Check if there are any .nc files
#  Check if there are any .nc files
if (length(nc_files) == 0) {
stop("No .nc files found in the directory.")
}
# Use the first .nc file found (adjust if you need to process multiple files)
nc_file <- nc_files[1]
# Open the .nc file
nc_data <- nc_open(nc_file)
# Extract a variable (adjust "variable_name" to the actual variable name you need)
var_name <- names(nc_data$var)[1]  # Assuming you want to extract the first variable
# Extract a variable
var_name <- names(nc_data$var)[1]
var_data <- ncvar_get(nc_data, var_name)
# Convert to a data frame (adjust as needed for your specific data)
df <- as.data.frame(var_data)
View(df)
# Close the .nc file
nc_close(nc_data)
# Save data to CSV
write.csv(df, file.path(nc_dir, "gridded_data.csv"), row.names = FALSE)
# Save data to CSV
write.csv(df, file.path(paste0(dir,"/combined_time_series.csv"), "gridded_data.csv"), row.names = FALSE)
# Save data to CSV
write.csv(df, file.path(dir, "gridded_data.csv"), row.names = FALSE)
# Print message
cat("Processed file:", nc_file, "\n")
# Print message
cat("Processed .asc files")
# Function to install and load packages
install_and_load <- function(package) {
if (!require(package, character.only = TRUE, quietly = TRUE)) {
cat("Installing package:", package, "\n")
install.packages(package, dependencies = TRUE, quiet = TRUE)
library(package, character.only = TRUE)
}
}
# Install and load required packages
packages <- c("httr", "rvest")
sapply(packages, install_and_load)
# Define the URLs and destination directory
urls <- list(
asc = "https://www.ncei.noaa.gov/data/noaa-global-surface-temperature/v6/access/timeseries/",
nc = "https://www.ncei.noaa.gov/data/noaa-global-surface-temperature/v6/access/gridded/"
)
dest_dir <- "../data/raw/"
# Create destination directory if it does not exist
if (!dir.exists(dest_dir)) {
dir.create(dest_dir, recursive = TRUE)
cat("Created directory:", dest_dir, "\n")
}
# Function to download files from a given URL
download_files <- function(base_url, pattern, dest_dir) {
tryCatch({
# Read the webpage
webpage <- read_html(base_url)
# Extract links that match the file extension pattern
links <- webpage %>%
html_nodes("a") %>%
html_attr("href") %>%
.[grepl(pattern, .)]
if (length(links) == 0) {
cat("No files matching pattern", pattern, "found at", base_url, "\n")
return()
}
# Define the full URLs of the files
file_urls <- paste0(base_url, links)
# Download each file
for (file_url in file_urls) {
file_name <- basename(file_url)
file_path <- file.path(dest_dir, file_name)
# Check if file already exists
if (file.exists(file_path)) {
cat("File already exists, skipping:", file_name, "\n")
} else {
# Download file
GET(file_url, write_disk(file_path, overwrite = TRUE))
cat("Downloaded:", file_name, "\n")
}
}
}, error = function(e) {
cat("Error occurred while downloading files from", base_url, ":", conditionMessage(e), "\n")
})
}
# Main function to orchestrate downloads
main <- function() {
cat("Starting file downloads...\n")
download_files(urls$asc, "\\.asc$", dest_dir)
download_files(urls$nc, "\\.nc$", dest_dir)
cat("All downloads completed.\n")
}
# Run the main function
main()
# Function to install and load packages
install_and_load <- function(package) {
if (!require(package, character.only = TRUE)) {
install.packages(package)
library(package, character.only = TRUE)
}
}
# Install and load required packages
packages <- c('data.table', 'ncdf4', 'raster')
sapply(packages, install_and_load)
# Set working directory
dir <- "../data/raw/"
# Process .asc files
process_asc_files <- function(dir) {
cat("Processing .asc files...\n")
file_list <- list.files(path = dir, pattern = "\\.asc$", full.names = TRUE)
if (length(file_list) == 0) {
cat("No .asc files found in the directory.\n")
return(NULL)
}
data_list <- lapply(file_list, fread, fill = TRUE)
combined_data <- rbindlist(data_list, fill = TRUE)
output_file <- file.path(dir, "combined_time_series.csv")
fwrite(combined_data, output_file)
cat("Processed", length(file_list), ".asc files. Output saved to", output_file, "\n")
}
# Process .nc file
process_nc_file <- function(dir) {
cat("Processing .nc file...\n")
nc_files <- list.files(path = dir, pattern = "\\.nc$", full.names = TRUE)
if (length(nc_files) == 0) {
cat("No .nc files found in the directory.\n")
return(NULL)
}
nc_file <- nc_files[1]
nc_data <- nc_open(nc_file)
var_name <- names(nc_data$var)[1]
var_data <- ncvar_get(nc_data, var_name)
df <- as.data.frame(var_data)
nc_close(nc_data)
output_file <- file.path(dir, "gridded_data.csv")
write.csv(df, output_file, row.names = FALSE)
cat("Processed file:", nc_file, "\nOutput saved to", output_file, "\n")
}
# Main execution
main <- function() {
process_asc_files(dir)
process_nc_file(dir)
cat("All processing completed.\n")
}
# Run the main function
main()
# Set working directory to the script's location
setwd(dirname(sys.frame(1)$ofile))
# Function to run R scripts
run_r_script <- function(script_name) {
script_path <- file.path("../data/R", script_name)
if (file.exists(script_path)) {
cat("Running", script_name, "...\n")
source(script_path)
cat(script_name, "completed.\n\n")
} else {
cat("Error:", script_name, "not found in ../data/R/\n")
}
}
# Function to run SQL script
run_sql_script <- function(script_name) {
script_path <- file.path("../data/SQL", script_name)
if (file.exists(script_path)) {
cat("Running", script_name, "...\n")
# You'll need to replace this with actual SQL execution code
# This is just a placeholder
system(paste("sqlite3 your_database.db <", script_path))
cat(script_name, "completed.\n\n")
} else {
cat("Error:", script_name, "not found in ../data/SQL/\n")
}
}
# Main execution
main <- function() {
cat("Starting data processing pipeline...\n\n")
# Run R scripts
run_r_script("data_downloader.R")
run_r_script("data_converter.R")
# Run SQL script
run_sql_script("data_cleaning.sql")
cat("Data processing pipeline completed.\n")
cat("Next steps: Use Tableau to visualize the cleaned data.\n")
}
# Run the main function
main()
#!/usr/bin/env Rscript
# runner.R
# Set working directory to the script's location
setwd(dirname(sys.frame(1)$ofile))
#!/usr/bin/env Rscript
# runner.R
# Set working directory to the project root
setwd(dirname(dirname(sys.frame(1)$ofile)))
#!/usr/bin/env Rscript
# runner.R
# Set working directory to the project root
setwd(dirname(dirname(sys.frame(1)$ofile)))
# Set working directory to the project root
setwd(dirname(dirname(sys.frame(1)$ofile)))
# Set working directory to the project root
setwd(dirname(dirname(sys.frame(1)$ofile)))
# Set working directory to the project root
setwd(dirname(dirname(sys.frame(1)$ofile)))
# Function to install and load packages
install_and_load <- function(package) {
if (!require(package, character.only = TRUE, quietly = TRUE)) {
cat("Installing package:", package, "\n")
install.packages(package, dependencies = TRUE, quiet = TRUE)
library(package, character.only = TRUE)
}
}
# Install and load the here package
install_and_load("here")
# Set the working directory to the project root
setwd(here::here())
# Function to run R scripts
run_r_script <- function(script_name) {
script_path <- here::here("R", script_name)
if (file.exists(script_path)) {
cat("Running", script_name, "...\n")
source(script_path)
cat(script_name, "completed.\n\n")
} else {
cat("Error:", script_name, "not found in R/\n")
}
}
# Main execution
main <- function() {
cat("Starting data processing pipeline...\n\n")
# Run R scripts
run_r_script("data_downloader.R")
run_r_script("data_converter.R")
run_r_script("data_cleaning.R")
cat("Data processing pipeline completed.\n")
cat("Next steps: Use Tableau to visualize the cleaned data.\n")
}
# Run the main function
main()
# runner.R
# Function to install and load packages
install_and_load <- function(package) {
if (!require(package, character.only = TRUE, quietly = TRUE)) {
cat("Installing package:", package, "\n")
install.packages(package, dependencies = TRUE, quiet = TRUE)
library(package, character.only = TRUE)
}
}
# Install and load the here package
install_and_load("here")
# Print the current working directory
cat("Current working directory:", getwd(), "\n")
# Print the project root directory as determined by here
cat("Project root directory:", here::here(), "\n")
# Function to run R scripts
run_r_script <- function(script_name) {
script_path <- here::here("R", script_name)
cat("Looking for script at:", script_path, "\n")
if (file.exists(script_path)) {
cat("Running", script_name, "...\n")
source(script_path)
cat(script_name, "completed.\n\n")
} else {
cat("Error:", script_name, "not found at", script_path, "\n")
}
}
# Main execution
main <- function() {
cat("Starting data processing pipeline...\n\n")
# Run R scripts
run_r_script("data_downloader.R")
run_r_script("data_converter.R")
run_r_script("data_cleaning.R")
cat("Data processing pipeline completed.\n")
cat("Next steps: Use Tableau to visualize the cleaned data.\n")
}
# Run the main function
main()
# runner.R
# Function to install and load packages
install_and_load <- function(package) {
if (!require(package, character.only = TRUE, quietly = TRUE)) {
cat("Installing package:", package, "\n")
install.packages(package, dependencies = TRUE, quiet = TRUE)
library(package, character.only = TRUE)
}
}
# Install and load the here package
install_and_load("here")
# Print the current working directory
cat("Current working directory:", getwd(), "\n")
# Print the project root directory as determined by here
cat("Project root directory:", here::here(), "\n")
# Function to run R scripts
run_r_script <- function(script_name) {
script_path <- file.path(here::here(), script_name)
cat("Looking for script at:", script_path, "\n")
if (file.exists(script_path)) {
cat("Running", script_name, "...\n")
source(script_path)
cat(script_name, "completed.\n\n")
} else {
cat("Error:", script_name, "not found at", script_path, "\n")
}
}
# Main execution
main <- function() {
cat("Starting data processing pipeline...\n\n")
# Run R scripts
run_r_script("data_downloader.R")
run_r_script("data_converter.R")
run_r_script("data_cleaning.R")
cat("Data processing pipeline completed.\n")
cat("Next steps: Use Tableau to visualize the cleaned data.\n")
}
# Run the main function
main()
# Function to install and load packages
install_and_load <- function(package) {
if (!require(package, character.only = TRUE, quietly = TRUE)) {
cat("Installing package:", package, "\n")
install.packages(package, dependencies = TRUE, quiet = TRUE)
library(package, character.only = TRUE)
}
}
# Install and load the here package
install_and_load("here")
# Print the current working directory
cat("Current working directory:", getwd(), "\n")
# Print the project root directory as determined by here
cat("Project root directory:", here::here(), "\n")
# Function to run R scripts
run_r_script <- function(script_name) {
script_path <- file.path(here::here(), script_name)
cat("Looking for script at:", script_path, "\n")
if (file.exists(script_path)) {
cat("Running", script_name, "...\n")
source(script_path)
cat(script_name, "completed.\n\n")
} else {
cat("Error:", script_name, "not found at", script_path, "\n")
}
}
# Main execution
main <- function() {
cat("Starting data processing pipeline...\n\n")
# Run R scripts
run_r_script("data_downloader.R")
run_r_script("data_converter.R")
run_r_script("data_cleaning.R")
cat("Data processing pipeline completed.\n")
cat("Next steps: Use Tableau to visualize the cleaned data.\n")
}
# Run the main function
main()
# cleanup
closeAllConnections()
# runner.R
# Function to install and load packages
install_and_load <- function(package) {
if (!require(package, character.only = TRUE, quietly = TRUE)) {
cat("Installing package:", package, "\n")
install.packages(package, dependencies = TRUE, quiet = TRUE)
library(package, character.only = TRUE)
}
}
# Install and load required packages
install_and_load("here")
install_and_load("DBI")
install_and_load("odbc")
# Print the current working directory
cat("Current working directory:", getwd(), "\n")
# Print the project root directory as determined by here
cat("Project root directory:", here::here(), "\n")
# Function to run R scripts
run_r_script <- function(script_name) {
script_path <- file.path(here::here(), script_name)
cat("Looking for script at:", script_path, "\n")
if (file.exists(script_path)) {
cat("Running", script_name, "...\n")
source(script_path)
cat(script_name, "completed.\n\n")
} else {
cat("Error:", script_name, "not found at", script_path, "\n")
}
}
# Function to run SQL scripts
run_sql_script <- function(script_name) {
script_path <- file.path(here::here(), "sql", script_name)
cat("Running SQL script:", script_path, "\n")
# Connect to the database
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "KENSQL",
Database = "GlobalTemperatureAnalysis",
Trusted_Connection = "Yes")
# Read the SQL script
sql_script <- readLines(script_path)
sql_script <- paste(sql_script, collapse = "\n")
# Execute the SQL script
tryCatch({
dbExecute(con, sql_script)
cat(script_name, "completed successfully.\n\n")
}, error = function(e) {
cat("Error executing", script_name, ":", e$message, "\n")
})
# Close the connection
dbDisconnect(con)
}
# Function to run PowerShell script
run_powershell_script <- function(script_name) {
script_path <- file.path(here::here(), "sql", script_name)
cat("Running PowerShell script:", script_path, "\n")
system(paste("powershell -ExecutionPolicy Bypass -File", script_path), intern = TRUE)
cat(script_name, "completed.\n\n")
}
cat("Starting data processing pipeline...\n\n")
# Run R scripts
run_r_script("data_downloader.R")
run_r_script("data_converter.R")
run_r_script("data_cleaning.R")
# Run SQL and PowerShell scripts
run_sql_script("store-and-preprocess.sql")
